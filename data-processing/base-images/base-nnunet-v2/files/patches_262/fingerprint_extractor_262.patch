diff --git a/nnunetv2/experiment_planning/dataset_fingerprint/fingerprint_extractor.py b/nnunetv2/experiment_planning/dataset_fingerprint/fingerprint_extractor.py
index 5f014e8..a96d67b 100644
--- a/nnunetv2/experiment_planning/dataset_fingerprint/fingerprint_extractor.py
+++ b/nnunetv2/experiment_planning/dataset_fingerprint/fingerprint_extractor.py
@@ -33,10 +33,18 @@ class DatasetFingerprintExtractor(object):
         self.dataset_json = load_json(join(self.input_folder, 'dataset.json'))
         self.dataset = get_filenames_of_train_images_and_targets(self.input_folder, self.dataset_json)
 
+        # for federated data fingerprinting
+        # set fed_num_clients=1 as default (also for local training)
+        fed_num_clients = os.getenv("FED_NUM_CLIENTS", None)
+        self.fed_num_clients = int(fed_num_clients) if fed_num_clients else 1
+        # set fed_global_fingerprint="estimate" as default to not write 10e7 voxels in data fingerprint
+        self.fed_global_fingerprint = os.getenv("FED_GLOBAL_FINGERPRINT", "estimate")
+
         # We don't want to use all foreground voxels because that can accumulate a lot of data (out of memory). It is
         # also not critically important to get all pixels as long as there are enough. Let's use 10e7 voxels in total
         # (for the entire dataset)
-        self.num_foreground_voxels_for_intensitystats = 10e7
+        self.num_foreground_voxels_for_intensitystats = (10e7 // self.fed_num_clients)
+
 
     @staticmethod
     def collect_foreground_intensities(segmentation: np.ndarray, images: np.ndarray, seed: int = 1234,
@@ -159,9 +167,11 @@ class DatasetFingerprintExtractor(object):
             #                 processes=self.num_processes, zipped=True, reader_writer_class=reader_writer_class,
             #                 num_samples=num_foreground_samples_per_case, disable=self.verbose)
             results = [i.get()[0] for i in r]
+            # results contains per sample: shape, spacing, list of all foreground_intensities, statistics, relative_size_after_cropping
 
             shapes_after_crop = [r[0] for r in results]
             spacings = [r[1] for r in results]
+            foreground_intensities_per_channel_per_case = [r[2][0].tolist() for r in results]
             foreground_intensities_per_channel = [np.concatenate([r[2][i] for r in results]) for i in
                                                   range(len(results[0][2]))]
             foreground_intensities_per_channel = np.array(foreground_intensities_per_channel)
@@ -185,11 +195,15 @@ class DatasetFingerprintExtractor(object):
                     'percentile_99_5': float(percentile_99_5),
                     'percentile_00_5': float(percentile_00_5),
                 }
+                # put v in fingerprint dependent on fed_global_fingerprint argument
+                if self.fed_global_fingerprint and self.fed_global_fingerprint == "accurate":
+                    print(f"KaapanaFed-adapted: {self.fed_global_fingerprint=} ==> We are sharing {self.num_foreground_voxels_for_intensitystats} voxels!")
+                    intensity_statistics_per_channel[i]["v"] = foreground_intensities_per_channel_per_case
 
             fingerprint = {
                     "spacings": spacings,
                     "shapes_after_crop": shapes_after_crop,
-                    'foreground_intensity_properties_per_channel': intensity_statistics_per_channel,
+                    "foreground_intensity_properties_per_channel": intensity_statistics_per_channel,
                     "median_relative_size_after_cropping": median_relative_size_after_cropping
                 }
 
