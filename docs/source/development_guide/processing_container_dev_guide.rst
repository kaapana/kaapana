.. _processing_container_dev_guide:

==================================
Developing a processing-container
==================================

A :term:`processing-container` is a container image, that processes data.
Such containers are commonly executed in tasks of a Workflow, e.g. for pre-pocessing, training or post-processing data.
We formulated a standward way for building processing-containers such that they are executable in Kaapana in the Task API.

These requirements are expressed in the `processing-container.json` file, which has to be part of any processing-container.
So make sure, that the Dockerfile for building the container image contains the following line:

.. code-block:: bash

    COPY files/processing-container.json /processing-container.json




The processing-container.json file
###################################

This file serves two purposes:

1. It communicates in a standardized way how to use this processing-container for data processing.
2. It contains all information that Kaapana needs to to execute as processing-container inside a task.

The json-schema for this file can be found here: TODO
Example processing-containers can be found here: TODO

A processing-container usually ships a specific tool and such a tool might support several usecases.
Therefore, the `processing-container.json` file can contain multiple task templates, that describe different usecases for the same tooling.

Each task template must contain the following information

Identifier 
----------
Users of this processing-container can declare which task template to use by specifying the corresponding identifier.


Description
------------
This should describe how this task template utilizes the tools in the container image to process data.
This can also contain high-level information about how the process expects input data to be structured and how results will be structured.


Environment variables
---------------------
It is a common concept that the execution of a container image can be cofigured via environment variables.
A task template should contain a list of configurable environment variables with descriptions on how they influence the processing of data.
An environment variable object must have the following fields:

* name
* value

It is highly recommended to also add the fields:

* description
* type
* choices
* adjustable

This will strongly improve the usability of the processing-container, as it ads clarity 
Furthermore, the Kaapana Web Interface can utilize these fields to show users how they can configure the task execution to their needs.


Input channels
--------------
Input data corresponds to the data that is processed during container runtime.
Many usecases require different types of data as input, e.g. image registration expects one fixed image and multiple moving images.
We assume, that the command that runs in the processing-container expects different types of data at different locations.
We understand each of these locations per data type as an input channels.

A task template must specify for each channel, where the data should be mounted inside the container.
As channels are identified by there name and need a description any input channel object requires the following fields:

* name
* mounted_path
* description

An additional feature provided by the Task API are scale rules for input channels.
You can specify how memory resources of the processing-container should be scaled based on the file sizes in your input channels.
More details will come TODO.


Output channels
------------------
Output data corresponds to all results that are generated during data-processing in form of files.
In order to distinguish different data types generated by the process we expect that generated files are structured according to their type,
e.g. the results of a training process usually consists of the trained model as well as logs from the training.
Similar to input channels a task template must specify one output channel for each data type created during the process.
Output channels consist of the same fields as input channels:

* name
* mounted_path
* description


Command [Optional]
-------------------
A container image can be shipped with multiple tools.
The command field specifies which command is executed for the corresponding that is executed in the container runtime as a list of strings.
If this is not specified the 

Resources [Optional]
---------------------
You can specify requests and limits of memory, CPU cores and GPU that the processing-container should use.


Executing a processing-container locally
#########################################

* Validating a processing-container.json file
* Creating a task
* Running a task locally in docker 





Using a processing-container in an Airflow DAG
###############################################


* Install task-api-extension
* No need to define a custom operator 
* Just use the KaapanaTaskOperator within the DAG
* How to specify IOChannelMap
* Link to example DAG

=======================================
Migrating a legacy processing-container
=======================================

